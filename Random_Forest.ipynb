{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Random Forest.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOb4D0P4eNCo7x+i9XNaT0A",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pushkarp26/Machine-Learning-of-energy-use-of-appliances-in-alow-energy-house/blob/main/Random_Forest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gih8CAdavOpL"
      },
      "source": [
        "#**Importing Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkptNxkhYJYZ"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "from google.colab import files\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import cross_validate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3tK_Jpmvh25"
      },
      "source": [
        "#**Data**\n",
        "From the previous notebooks I have saved the predictor and target feature datasets.\n",
        "So, will use them directly here instead of doing all the preliminary steps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsCUZoDABQy1",
        "outputId": "5a780c86-8555-49c9-d617-5523b13cc59c"
      },
      "source": [
        "X = pd.read_csv(\"predictor.csv\")\n",
        "y = pd.read_csv(\"target.csv\")\n",
        "X.drop(\"Unnamed: 0\",axis=1,inplace=True)\n",
        "y.drop(\"Unnamed: 0\",axis=1,inplace=True)\n",
        "\n",
        "print(\"Predictor features:\\n {}\\n\\nTarget Features:\\n {}\".format(X.head(),y.head()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predictor features:\n",
            "    Kitchen_Temp  Kitchen_Humidity  Living_room_Temp  ...        rv2  Weekday    NSM\n",
            "0         19.89         47.596667              19.2  ...  13.275433        0  61200\n",
            "1         19.89         46.693333              19.2  ...  18.606195        0  61800\n",
            "2         19.89         46.300000              19.2  ...  28.642668        0  62400\n",
            "3         19.89         46.066667              19.2  ...  45.410389        0  63000\n",
            "4         19.89         46.333333              19.2  ...  10.084097        0  63600\n",
            "\n",
            "[5 rows x 28 columns]\n",
            "\n",
            "Target Features:\n",
            "    Total_Energy_Consumption\n",
            "0                        90\n",
            "1                        90\n",
            "2                        80\n",
            "3                        90\n",
            "4                       100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPzYM9wqw7DT"
      },
      "source": [
        "Splitting the data into Training and Testing sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hI5IUtKxEtGL",
        "outputId": "d095fb7f-300d-4970-fb02-c34276d1d7ef"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "y_array = np.asarray(y)\n",
        "y_array = y_array.ravel()\n",
        "\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y_array,test_size=0.3)\n",
        "print(\"X_train:\",X_train.shape,\"\\t\",\"y_train:\",y_train.shape,\"\\n\",'X_test:',\n",
        "       X_test.shape,\"\\t\",\"y_test:\",y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train: (13814, 28) \t y_train: (13814,) \n",
            " X_test: (5921, 28) \t y_test: (5921,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PY0KFTFyxDDI"
      },
      "source": [
        "#**Base Model**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l--6m8bKGZ5d",
        "outputId": "c78b5c5d-927f-46ba-97b3-d4ab25a33bc7"
      },
      "source": [
        "rfc = RandomForestRegressor(n_estimators=10,random_state=42)\n",
        "rfc.fit(X_train,y_train)                                                         #training the model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
              "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "                      max_samples=None, min_impurity_decrease=0.0,\n",
              "                      min_impurity_split=None, min_samples_leaf=1,\n",
              "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
              "                      n_estimators=10, n_jobs=None, oob_score=False,\n",
              "                      random_state=42, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Thdf0YdNyJTr"
      },
      "source": [
        "Checking the *Accuracy* score of our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azFbuoeRJjxs",
        "outputId": "5ce97932-a943-4019-c8cb-77a7845e73ef"
      },
      "source": [
        "print(\"Accuracy Score for Train data: {}\\n Accuracy Score for Test data: {}\".\n",
        "      format(rfc.score(X_train,y_train),rfc.score(X_test,y_test)))                                                      #"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Score for Train data: 0.914981091806844\n",
            " Accuracy Score for Test data: 0.5188051358559009\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xITAXnKRySoR"
      },
      "source": [
        "Evaluating errors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3aWti8XZLpcF",
        "outputId": "367b0449-a1ef-4125-81fa-6820fa5156af"
      },
      "source": [
        "from sklearn import metrics\n",
        "pred = rfc.predict(X_test)\n",
        "print('Mean Absolute Error (MAE):', metrics.mean_absolute_error(y_test, pred))   #mean absolute error\n",
        "print('Mean Squared Error (MSE):', metrics.mean_squared_error(y_test, pred))     #mean squared error\n",
        "print('Root Mean Squared Error (RMSE):', np.sqrt(metrics.mean_squared_error(\n",
        "    y_test, pred)))                                                              #Root Mean Squared Error \n",
        "# mape = np.mean(np.abs((y_test - pred) / np.abs(y_test)))\n",
        "# print('Mean Absolute Percentage Error (MAPE):', round(mape * 100, 2))\n",
        "# print('Accuracy:', round(100*(1 - mape), 2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean Absolute Error (MAE): 32.10103023137984\n",
            "Mean Squared Error (MSE): 4261.902837358555\n",
            "Root Mean Squared Error (RMSE): 65.28325081794377\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqmp-YPktdHp"
      },
      "source": [
        "#**RandomSearchCV**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHPsVXZYtiLQ",
        "outputId": "ceb87774-f413-479f-d48e-93047ab44eb8"
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# Number of trees in random forest\n",
        "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 200, num = 20)]\n",
        "# Number of features to consider at every split\n",
        "max_features = ['auto', 'sqrt']\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [int(x) for x in np.linspace(5, 110, num = 22)]\n",
        "max_depth.append(None)\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 5, 10]\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "# Method of selecting samples for training each tree\n",
        "bootstrap = [True, False]\n",
        "# Create the random grid\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'bootstrap': bootstrap}\n",
        "print(random_grid)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'n_estimators': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200], 'max_features': ['auto', 'sqrt'], 'max_depth': [5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100, 105, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEikgfiYtiUH",
        "outputId": "7cb0dce9-6358-41f2-e542-dec5822200c7"
      },
      "source": [
        "# Use the random grid to search for best hyperparameters\n",
        "# First create the base model to tune\n",
        "rf = RandomForestRegressor()\n",
        "# Random search of parameters, using 3 fold cross validation, \n",
        "# search across 100 different combinations, and use all available cores\n",
        "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = \n",
        "                               random_grid, n_iter = 100, cv = 3, verbose=2,\n",
        "                               random_state=42, n_jobs = -1)\n",
        "# Fit the random search model\n",
        "rf_random.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  3.8min\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed: 26.3min\n",
            "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 51.5min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3, error_score=nan,\n",
              "                   estimator=RandomForestRegressor(bootstrap=True,\n",
              "                                                   ccp_alpha=0.0,\n",
              "                                                   criterion='mse',\n",
              "                                                   max_depth=None,\n",
              "                                                   max_features='auto',\n",
              "                                                   max_leaf_nodes=None,\n",
              "                                                   max_samples=None,\n",
              "                                                   min_impurity_decrease=0.0,\n",
              "                                                   min_impurity_split=None,\n",
              "                                                   min_samples_leaf=1,\n",
              "                                                   min_samples_split=2,\n",
              "                                                   min_weight_fraction_leaf=0.0,\n",
              "                                                   n_estimators=100,\n",
              "                                                   n_jobs=None, oob_score=Fals...\n",
              "                                        'max_depth': [5, 10, 15, 20, 25, 30, 35,\n",
              "                                                      40, 45, 50, 55, 60, 65,\n",
              "                                                      70, 75, 80, 85, 90, 95,\n",
              "                                                      100, 105, 110, None],\n",
              "                                        'max_features': ['auto', 'sqrt'],\n",
              "                                        'min_samples_leaf': [1, 2, 4],\n",
              "                                        'min_samples_split': [2, 5, 10],\n",
              "                                        'n_estimators': [10, 20, 30, 40, 50, 60,\n",
              "                                                         70, 80, 90, 100, 110,\n",
              "                                                         120, 130, 140, 150,\n",
              "                                                         160, 170, 180, 190,\n",
              "                                                         200]},\n",
              "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
              "                   return_train_score=False, scoring=None, verbose=2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9muVvo_tigO",
        "outputId": "d56a222c-cc5b-4410-fc0d-b11cd53f3cd0"
      },
      "source": [
        "rf_random.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bootstrap': False,\n",
              " 'max_depth': 95,\n",
              " 'max_features': 'sqrt',\n",
              " 'min_samples_leaf': 1,\n",
              " 'min_samples_split': 2,\n",
              " 'n_estimators': 90}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvLtShcfticw"
      },
      "source": [
        "rf_random.cv_results_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4wn3q-KAyk0"
      },
      "source": [
        "#**Evaluation Function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELQWe8NetiQu"
      },
      "source": [
        "def evaluate(model, test_features, test_labels):\n",
        "    predictions = model.predict(test_features)\n",
        "    errors = abs(predictions - test_labels)\n",
        "    mape = 100 * np.mean(errors / test_labels)\n",
        "    accuracy = 100 - mape\n",
        "    print('Model Performance')\n",
        "    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
        "    print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
        "    \n",
        "    return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Q_f0JSCB8Ye"
      },
      "source": [
        "#####**Evaluate the Default Model**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5JSCsdjth5z",
        "outputId": "8963b3d2-1170-4653-8018-3d436775d967"
      },
      "source": [
        "base_model = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
        "base_model.fit(X_train, y_train)\n",
        "base_accuracy = evaluate(base_model, X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Performance\n",
            "Average Error: 34.5386 degrees.\n",
            "Accuracy = 65.66%.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WlCoD4_IGaY"
      },
      "source": [
        "#####**Evaluate the Best Random Search Model**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qq1LYecILN0",
        "outputId": "a94f3fb9-685b-459d-9035-c4cc40d5ca62"
      },
      "source": [
        "best_random = rf_random.best_estimator_\n",
        "random_accuracy = evaluate(best_random, X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Performance\n",
            "Average Error: 29.2471 degrees.\n",
            "Accuracy = 71.56%.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isEJ0FnUTl7u",
        "outputId": "27325021-e4ba-4896-b5a4-a78884f24bcd"
      },
      "source": [
        "print('Improvement of {:0.2f}%.'.format( 100 * (random_accuracy - base_accuracy) / base_accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Improvement of 8.98%.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEWLYCflT2xr"
      },
      "source": [
        "#**Grid Search**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6ON8CtKT-DK"
      },
      "source": [
        "We can now perform grid search building on the result from the random search. We will test a range of hyperparameters around the best values returned by random search."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOOvsHWvT7Lk"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Create the parameter grid based on the results of random search \n",
        "param_grid = {\n",
        "    'bootstrap': [False],\n",
        "    'max_depth': [100,110,120,130,140,150],\n",
        "    'max_features': ['sqrt'],\n",
        "    'min_samples_leaf': [1, 2, 3],\n",
        "    'min_samples_split': [1, 2, 4, 6],\n",
        "    'n_estimators': [80, 100, 110, 120]\n",
        "}\n",
        "\n",
        "# Create a base model\n",
        "rf = RandomForestRegressor(random_state = 42)\n",
        "\n",
        "# Instantiate the grid search model\n",
        "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
        "                          cv = 3, n_jobs = -1, verbose = 2, return_train_score=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2KNJIelT7TL",
        "outputId": "fe91b96a-e890-4c6f-b154-0073a7ff60f8"
      },
      "source": [
        "grid_search.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 288 candidates, totalling 864 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  2.2min\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:  9.0min\n",
            "[Parallel(n_jobs=-1)]: Done 361 tasks      | elapsed: 21.9min\n",
            "[Parallel(n_jobs=-1)]: Done 644 tasks      | elapsed: 39.1min\n",
            "[Parallel(n_jobs=-1)]: Done 864 out of 864 | elapsed: 53.0min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3, error_score=nan,\n",
              "             estimator=RandomForestRegressor(bootstrap=True, ccp_alpha=0.0,\n",
              "                                             criterion='mse', max_depth=None,\n",
              "                                             max_features='auto',\n",
              "                                             max_leaf_nodes=None,\n",
              "                                             max_samples=None,\n",
              "                                             min_impurity_decrease=0.0,\n",
              "                                             min_impurity_split=None,\n",
              "                                             min_samples_leaf=1,\n",
              "                                             min_samples_split=2,\n",
              "                                             min_weight_fraction_leaf=0.0,\n",
              "                                             n_estimators=100, n_jobs=None,\n",
              "                                             oob_score=False, random_state=42,\n",
              "                                             verbose=0, warm_start=False),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'bootstrap': [False],\n",
              "                         'max_depth': [100, 110, 120, 130, 140, 150],\n",
              "                         'max_features': ['sqrt'],\n",
              "                         'min_samples_leaf': [1, 2, 3],\n",
              "                         'min_samples_split': [1, 2, 4, 6],\n",
              "                         'n_estimators': [80, 100, 110, 120]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
              "             scoring=None, verbose=2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AS3kcEPT7P1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65ee7518-024e-4587-fe48-aa8a3803df27"
      },
      "source": [
        "grid_search.best_params_"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bootstrap': False,\n",
              " 'max_depth': 100,\n",
              " 'max_features': 'sqrt',\n",
              " 'min_samples_leaf': 1,\n",
              " 'min_samples_split': 2,\n",
              " 'n_estimators': 120}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "001TVgmDXjke"
      },
      "source": [
        "#####**Evaluate the Best Model from Grid Search**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioEbzXP0T7D9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91c636a0-efdb-4fca-e077-1805ac1b8bb8"
      },
      "source": [
        "best_grid = grid_search.best_estimator_\n",
        "grid_accuracy = evaluate(best_grid, X_test, y_test)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Performance\n",
            "Average Error: 29.0743 degrees.\n",
            "Accuracy = 71.64%.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8uAJVZsT3JX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6e6fe72-c1ec-4c19-a548-d839083802ab"
      },
      "source": [
        "print('Improvement of {:0.2f}%.'.format( 100 * (grid_accuracy - base_accuracy) /\n",
        "                                        base_accuracy))\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Improvement of 9.10%.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLWUp9cykwaP"
      },
      "source": [
        "#**Conclusion**\n",
        "Chronologically we performed RandomSearchCV first on the model, where we the error was MAE was significantly reduced from 34.586 to 29.247 and ACCURACY increased dramtically from 65.66% to 71.56%.\n",
        "\n",
        "Then we performed GridsearchCV from the around the best parameters obtained from RandomSearchCV.Then the MAE was slightly reduced from 29.247 to 29.073 and ACCURACY achieved was 71.64%.\n",
        "\n",
        "So from the above results it is evident that furter tuning won't make much difference in the ACCURACY and thus we concluded our quest of obtainig the best model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSsslYZCT3Pm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}